# ğŸ§  Smart Knowledge Repository - Production v2.0

> AI-Powered Team Intelligence Platform with Modern Modular Architecture

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- OpenAI API key

### Installation

```bash
# 1. Clone repository
git clone <your-repo-url>
cd "Smart Knowledge Repository"

# 2. Install dependencies
pip install -r requirements.txt

# 3. Set up environment variables
# Create .env file with your OpenAI API key
echo "OPENAI_API_KEY=your-api-key-here" > .env

# 4. Run the application
streamlit run main.py
```

## ğŸ“ Project Structure

```
project_root/
â”œâ”€â”€ main.py                          # Application entry point
â”œâ”€â”€ src/                             # Source code (modular architecture)
â”‚   â”œâ”€â”€ scrapers/                    # Web scraping modules
â”‚   â”‚   â”œâ”€â”€ profile_scraper.py       # Profile extraction logic
â”‚   â”‚   â””â”€â”€ content_discovery.py    # Team page discovery
â”‚   â”œâ”€â”€ database/                    # Data persistence layer
â”‚   â”‚   â”œâ”€â”€ models.py                # Data models & schemas
â”‚   â”‚   â”œâ”€â”€ repository.py            # Database operations
â”‚   â”‚   â””â”€â”€ migrations.py            # Schema migrations
â”‚   â”œâ”€â”€ search/                      # Search & indexing
â”‚   â”‚   â”œâ”€â”€ vector_search.py         # Semantic vector search
â”‚   â”‚   â””â”€â”€ indexing.py              # Embedding creation
â”‚   â”œâ”€â”€ services/                    # Business logic layer
â”‚   â”‚   â”œâ”€â”€ knowledge_service.py     # Knowledge queries
â”‚   â”‚   â”œâ”€â”€ chat_service.py          # Conversational AI
â”‚   â”‚   â””â”€â”€ scraping_service.py      # Scraping orchestration
â”‚   â””â”€â”€ ui/                          # User interface components
â”‚       â”œâ”€â”€ chat_interface.py        # Chat UI
â”‚       â”œâ”€â”€ browse_interface.py      # Profile browsing
â”‚       â””â”€â”€ admin_interface.py       # Admin panel
â”œâ”€â”€ data/                            # Data storage
â”‚   â”œâ”€â”€ leadership.db                # SQLite database
â”‚   â””â”€â”€ embeddings/                  # Vector embeddings cache
â”œâ”€â”€ config/                          # Configuration files
â”‚   â””â”€â”€ scraping_targets.yaml        # Scraping configuration
â””â”€â”€ docs/                            # Documentation
    â”œâ”€â”€ DATABASE_EXPLAINED.md        # Database architecture
    â””â”€â”€ ARCHITECTURE_EXPLAINED.md    # System design
```

## ğŸ¯ Features

### ğŸ’¬ AI Chat Interface
- Natural language Q&A about team members
- Context-aware responses
- Department filtering
- Conversation history

### ğŸ‘¥ Profile Browsing
- Search by name, role, bio, or department
- AI semantic search or traditional text search
- Photo display with smart loading
- Department organization

### âš™ï¸ Admin Panel
- Web scraping from any company website
- Automatic team page discovery
- Deep profile extraction
- Vector embedding management
- Database management tools

### ğŸ” Smart Search
- **Vector Search**: AI-powered semantic understanding
- **FTS5 Search**: Fast full-text search
- **Hybrid Search**: Combine both for best results
- Department and role filtering

### ğŸ›¡ï¸ Hallucination Prevention
- Only answers based on scraped data
- Source attribution
- Confidence scoring
- Graceful handling of unknown queries

## ğŸ—ï¸ Architecture

### Service Layer Pattern
The application follows a clean service-oriented architecture:

- **UI Layer** (`src/ui/`): Streamlit components, user interactions
- **Service Layer** (`src/services/`): Business logic, orchestration
- **Data Layer** (`src/database/`, `src/search/`): Persistence, search
- **Scraper Layer** (`src/scrapers/`): Data acquisition

### Benefits
- âœ… **Separation of Concerns**: Each module has a single responsibility
- âœ… **Testability**: Services can be tested independently
- âœ… **Maintainability**: Easy to find and update code
- âœ… **Scalability**: Add new features without modifying existing code
- âœ… **Production-Ready**: Professional structure for deployment

## ğŸ”§ Configuration

### Scraping Targets (`config/scraping_targets.yaml`)
```yaml
default_target:
  name: Amzur Technologies
  url: https://amzur.com/
  deep_scrape: true

scraping:
  timeout: 30
  retry_attempts: 3

database:
  path: data/leadership.db

ui:
  app_title: Smart Knowledge Repository
  layout: wide
```

## ğŸ“Š Database Schema

### Profiles Table
- `id`: Unique identifier
- `name`: Person's name
- `role`: Job title/position
- `bio`: Biography text
- `photo_url`: Profile photo URL
- `contact`: Email address
- `phone`: Phone number
- `linkedin`: LinkedIn profile URL
- `twitter`: Twitter handle
- `department`: Department/team name
- `profile_url`: Source profile URL
- `embedding`: JSON array of vector embeddings
- `created_at`: Timestamp

### FTS5 Virtual Table
- Full-text search index on: name, role, bio, department

## ğŸ” Security

- âœ… API keys stored in `.env` (never committed to git)
- âœ… `.gitignore` configured for sensitive files
- âœ… Input validation on all forms
- âœ… SQL injection prevention via parameterized queries

## ğŸš€ Deployment

### Local Development
```bash
streamlit run main.py
```

### Production Deployment
```bash
# Using Streamlit Cloud
streamlit run main.py --server.port 8501 --server.address 0.0.0.0

# Using Docker (create Dockerfile first)
docker build -t smart-knowledge-repo .
docker run -p 8501:8501 smart-knowledge-repo
```

## ğŸ“ˆ Performance

- **Search Speed**: < 100ms for vector search (cached embeddings)
- **Scraping**: ~2-5 seconds per profile (deep scrape)
- **Database**: SQLite with FTS5 (handles 1000+ profiles easily)
- **Memory**: ~100MB for typical usage

## ğŸ§ª Testing

```bash
# Run tests
python -m pytest tests/

# Check specific features
python test_enhanced_features.py
python final_verification.py
```

## ğŸ“ Usage Examples

### Add a New Website
1. Go to **Admin** tab
2. Enter website URL (e.g., `https://company.com`)
3. Enable "Deep Scrape" for detailed profiles
4. Click "Start Scraping"

### Chat with AI
1. Go to **Chat** tab
2. Ask questions like:
   - "Who are the software engineers?"
   - "Tell me about the leadership team"
   - "Who works in data science?"

### Browse Profiles
1. Go to **Browse Profiles** tab
2. Use search bar or department filter
3. Toggle AI semantic search on/off
4. View profile photos and details

## ğŸ¤ Contributing

This is a production-grade application. When contributing:

1. Follow the existing modular structure
2. Add new features as services
3. Write tests for business logic
4. Update documentation
5. Keep UI components separate from logic

## ğŸ“„ License

[Your License Here]

## ğŸ†˜ Troubleshooting

### "No profiles found"
- Make sure you've scraped a website first (Admin tab)
- Check that the website has a team/leadership page

### "OpenAI API error"
- Verify your API key in `.env` file
- Check your OpenAI account has credits

### Photos not loading
- Some websites block external photo loading
- Try re-scraping with deep scrape enabled

### Import errors
- Make sure all dependencies are installed: `pip install -r requirements.txt`
- Check Python version is 3.8+

## ğŸ“ Support

For issues, questions, or contributions, please open an issue on GitHub.

---

**Built with** â¤ï¸ **using Python, Streamlit, OpenAI, and SQLite**
